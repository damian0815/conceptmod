# Use the specified base image
FROM runpod/stable-diffusion:web-automatic-6.0.0

RUN \
  pip3 install imageio moviepy opencv-python ftfy datasets scikit-image && \
  pip3 install git+https://github.com/openai/CLIP.git --no-deps


# Clone the required repositories and install dependencies
RUN git clone https://github.com/CompVis/stable-diffusion.git /conceptmod && \
    git clone https://github.com/ntc-ai/conceptmod /conceptmod_tmp && \
    rsync -avh --force /conceptmod_tmp/* /conceptmod && \
    rm -rf /conceptmod_tmp && \
    cd /conceptmod && \
    git clone https://github.com/THUDM/ImageReward

COPY smile.safetensors /stable-diffusion-webui/models/Lora/smile.safetensors


RUN echo 'echo "Installing dependencies..."' > ~/.bashrc
RUN git clone https://github.com/kohya-ss/sd-scripts.git /sd-scripts && \
  cd /sd-scripts && \
  python3.10 -m venv lora && \
  source lora/bin/activate && \
  pip install --upgrade pip && \
  pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cu117/torch_stable.html && \
  pip install -r requirements.txt

RUN git clone https://github.com/CompVis/taming-transformers.git /taming-transformers

RUN echo 'echo " - - - this may take a minute - - - "' >> /root/.bashrc

# Create the installdeps.sh script and add it to .bashrc
RUN echo 'pip install --upgrade pip' > /conceptmod/installdeps.sh && \
    echo 'pip install omegaconf einops torchmetrics datasets torch torchvision numpy scipy scikit-image scikit-learn tqdm lmdb' >> /conceptmod/installdeps.sh && \
    echo 'pip install imageio moviepy opencv-python ftfy datasets scikit-image' >> /conceptmod/installdeps.sh && \
    echo 'pip install git+https://github.com/openai/CLIP.git@main#egg=clip' >> /conceptmod/installdeps.sh && \
    echo 'cd /conceptmod/ImageReward' >> /conceptmod/installdeps.sh && \
    echo 'python setup.py develop > /dev/null 2>&1' >> /conceptmod/installdeps.sh && \
    echo 'cd /taming-transformers' >> /conceptmod/installdeps.sh && \
    echo 'python setup.py develop > /dev/null 2>&1' >> /conceptmod/installdeps.sh && \
    echo 'source /workspace/conceptmod/installdeps.sh > /dev/null 2>&1' >> ~/.bashrc && \
    echo 'rsync -a --remove-source-files /conceptmod/* /workspace/conceptmod/ && cd /workspace/conceptmod' >> ~/.bashrc && \
    echo 'rsync -a --remove-source-files /sd-scripts /workspace/conceptmod/sd-scripts' >> ~/.bashrc
# echo 'ln -s /workspace/conceptmod/models /workspace/stable-diffusion-webui/models/Stable-diffusion/conceptmod' >> ~/.bashrc && \

RUN echo 'echo "Welcome to conceptmod. Train on a phrase or animate a lora."' >> /root/.bashrc
RUN echo 'echo "https://civitai.com/tag/conceptmod?sort=Newest has example phrases in the model descriptions."' >> /root/.bashrc
RUN echo 'echo "https://github.com/ntc-ai/conceptmod has more documentation."' >> /root/.bashrc
RUN echo 'echo ""' >> /root/.bashrc
RUN echo 'echo "Transfer your chosen checkpoint in safetensors format to /workspace/stable-diffusion-webui/models/Stable-diffusion/mycheckpoint.safetensors then select it within A111 (In the Connect -> Connect via HTTP (Port 3000))"' >> /root/.bashrc
RUN echo 'echo ""' >> /root/.bashrc
RUN echo 'echo "Example training command: python3 train-scripts/train-esd.py --prompt \"~laugh\" --train_method selfattn --ckpt_path /workspace/stable-diffusion-webui/models/Stable-diffusion/mycheckpoint.safetensors"' >> /root/.bashrc
RUN echo 'echo ""' >> /root/.bashrc
RUN echo 'echo "Example animation command: python3 lora_anim.py -s 0 -e 2 -l smile -lp \", smile\""' >> /root/.bashrc


# Update the relauncher.py script to add --api flag
RUN sed -i 's/launch_string = "\/workspace\/stable-diffusion-webui\/webui.sh -f"/launch_string = "\/workspace\/stable-diffusion-webui\/webui.sh -f --api"/' /stable-diffusion-webui/relauncher.py
EXPOSE 3000
# Set the working directory
WORKDIR /conceptmod
# Run the anim.sh script
CMD ["bash", "/start.sh"]
